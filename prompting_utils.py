import os
import json
import re

def read_schema(schema_path):
    '''
    Read the .schema file
    '''
    try:
        with open(schema_path, 'r') as f:
            schema_content = f.read()
            
            # Try to parse as JSON
            try:
                schema_data = json.loads(schema_content)
                return process_json_schema(schema_data)
            except json.JSONDecodeError:
                # If not valid JSON, use the original parsing approach
                return process_text_schema(schema_content)
    except FileNotFoundError:
        print(f"Warning: Schema file {schema_path} not found.")
        return {}

#This function is generated by an LLM, I asked for regex commands for each of these patterns. Note that I still
#came up with the different ways to extract queries.
def extract_sql_query(response):
    '''
    Extract the SQL query from the model's response
    '''
    sql_code_block = re.search(r'```(?:sql|SQL)(.*?)```', response, re.DOTALL)
    if sql_code_block:
        return sql_code_block.group(1).strip()
    
    #Look for SQL between ``` and ```
    code_block = re.search(r'```(.*?)```', response, re.DOTALL)
    if code_block:
        return code_block.group(1).strip()
    
    #Look for SQL after "SQL:" or "Query:"
    sql_after_label = re.search(r'(?:SQL|Query):\s*(.*?)(?:\n\n|$)', response, re.DOTALL)
    if sql_after_label:
        return sql_after_label.group(1).strip()
    
    #Look for text that resembles a SQL query
    sql_query = re.search(r'(SELECT\s+.*?)(;|\n\n|$)', response, re.DOTALL | re.IGNORECASE)
    if sql_query:
        return sql_query.group(1).strip() + ';'
    
    #return the last part of the response as a fallback
    lines = response.strip().split('\n')
    non_empty_lines = [line for line in lines if line.strip()]
    if non_empty_lines:
        return non_empty_lines[-1]
    
    # If all else fails, return empty string
    return ""

def save_logs(output_path, sql_em, record_em, record_f1, error_msgs):
    '''
    Save the logs of the experiment to files.
    You can change the format as needed.
    '''
    with open(output_path, "w") as f:
        f.write(f"SQL EM: {sql_em}\nRecord EM: {record_em}\nRecord F1: {record_f1}\nModel Error Messages: {error_msgs}\n")

def process_json_schema(schema_data):
    '''
    Process schema data in JSON format
    '''
    processed_schema = {
        'tables': {},
        'relationships': [],
        'types': schema_data.get('types', {})
    }

    if 'ents' in schema_data:
        for table_name, table_info in schema_data['ents'].items():
            columns = []
            column_types = {}
            
            # Extract columns and their types
            for column_name, column_info in table_info.items():
                columns.append(column_name)
                if 'type' in column_info:
                    type_name = column_info['type']
                    column_types[column_name] = type_name
            
            processed_schema['tables'][table_name] = {
                'columns': columns,
                'column_types': column_types
            }
    
    return processed_schema

def process_text_schema(schema_content):
    '''
    Process schema data in text format
    '''
    schema_info = {}
    return schema_info

def load_alignment_data(alignment_path):
    '''
    Load alignment data that maps natural language terms to database terms
    '''
    alignment_dict = {}
    
    try:
        with open(alignment_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line:
                    parts = line.split('\t')
                    if len(parts) == 2:
                        nl_term, db_term = parts
                        alignment_dict[nl_term.lower()] = db_term
    except FileNotFoundError:
        print(f"Warning: Alignment file {alignment_path} not found.")
    
    return alignment_dict